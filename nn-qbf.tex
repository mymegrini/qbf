\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amssymb, bm}
\usepackage{mathtools, bm}
\usepackage{mathrsfs}
\usepackage{stmaryrd}
\usepackage{graphicx}
%\usepackage[]{algorithm2e}
\usepackage[]{algorithm}
\usepackage[]{algorithmic}

% fonction pour définir une fonction 
\newcommand{\fonction}[5]{
	\begin{array}{ccccc}
#1 & : & #2 & \to & #3\\
	& & #4 & \mapsto & #5\\ 
	\end{array}
}

\begin{document}
\section[Titre plus court]{Les Neuronnes}

Le premier modèle mathématique et informatique du neuronne biologique a été donné par Warren McCulloh et Walter Pitts en 1943.
Ce modèle inspiré de la neurobiologique, fait intervenir n entrées auxquelles des fonctions y seront appliquées afin d'en obtenir une sortie.
Voici une définition plus formelle de ce modèle qu'on nomme: Modèle de McCulloh-Pitts     

\subsection{Définition: Modèle de McCulloh-Pitts}
	Soit la fonction  

	\[\fonction{\varphi}{\mathbb{R}^n}{\left\{0,1\right\}}{(x_1,....,x_n)}{\varphi(x_1,....,x_n)} \]

	tel que  
	\[\varphi (x_1,...,x_n) = g(f(x_1,....,x_n)). \]  

	\begin{enumerate}
		\item $f$ est définie comme étant la fonction somme 
		\[\fonction{f}{\mathbb{R}^n}{\mathbb{R}}{(x_1,....,x_n)}{\sum_{i=1}^{n} {x_i}} \] 
		\item On appelle $g$ la fonction d'activation à seuil. Celle-ci est définie de la manière suivante :

		\[g(x) = \begin{cases} 0 &\mbox{Si } x < \theta \\
				 1 & \mbox{Si } x \geq \theta
	 		 \end{cases} 
		\]
	\end{enumerate}
	
	\textbf{Remarque} : La valeur $\theta$  qu'on utilise dans la fonction $g$ est appelée le seuil.\\
	

Le modèle de McCulloh-Pitts a été décliné de multiple manière au cours du temps. Les déclinaisons auxquelles nous allons nous intérèsser sont appelé le modèle Perceptron et le modèle Sigmoid. Ces deux modèles introduisent la notion de poids qui est au coeur du processus d'apprentissage d'un réseau de neuronne. 

	\subsection{Définition: Modèle Perceptron}
		Le premier modèle du Perceptron a été introduit en 1958 par Frank Rosenblatt. Celui-ci a ensuite été repris et perfectionné dans les années soixante par Minsky et Papert. Ce modèle reprend la définition précédente sauf que pour chaque entrée $x_i$ ($i$ $\in$ $\llbracket 1~;~n \rrbracket$) on y associera une valeur (les fameux poids) $w_i$ $\in$ $\mathbb{R}$. 
		On définit alors la fonction $f$ de la façon suivante : 
		
		\[\fonction{f}{\mathbb{R}^n}{\mathbb{R}}{(x_1,....x_n)}{\sum_{i=1}^{n} {w_ix_i}}. \]

	
	\textbf{Remarque} : On note parfois \[b = -\theta \]  et on appel cette valeur le bias (ou inclinaison en français). La fonction $g$ est alors définit de la manière suivante :   
		\[g(x) = \begin{cases} 0 &\mbox{Si } x + b < 0 \\
				 1 & \mbox{Si } x + b \geq 0
	 		 \end{cases} \] \\ 

	 
Cette notion de poids va intervenir dans le processus d'apprentissage d'un réseau de neuronne. Le but de ce processus, sera de trouver les bonnes valeurs à associer aux entrées afin que le réseau de neuronne produise la meilleure sortie possible. Pour répondre au besoin du processus d'apprentissage, l'algorithme de la déscente de gradient sera utilisé. Nous détaillerons plus tard cet algorithme mais le principe de celui-ci est d'ajuster petit à petit les poids afin d'affiner la sortie du réseau de neuronne vers la valeur voulue. Cet affinement implique que la sortie $s$ $\in$ $\left[0,1\right]$, cependant la fonction $g$ ne sera  plus une fonction en escalier mais une fonction continue. Le Perceptron ne répondant plus à ces critères, le Sigmoid a été introduit. \\

	\subsection{Définition: Modèle Sigmoid}
	 Le modèle Sigmoid est défini de la même manière que le modèle perceptron mais il y diffère à la fonction $g$. La fonction $g$ aura pour particularité d'être continue. On appelle cette fonction, la fonction sigmoid.  
		  \[ \fonction{g}{\mathbb{R}}{\left[0,1\right]}{x}{ \frac{1}{1+ e^{-x}}} \]
		
	\subsection{Définition: Réseau de Neuronne}
 	Un réseau de neuronne est un ensemble de neuronnes connectés entre eux. Ce réseau est composé de plusieurs couches : 
	\begin{enumerate}	
		\item la couche d'entrée : Cette couche est composée de neuronnes dont leurs entrées n'est pas la sortie d'autre neuronne. 
		\item la couche cachée : Cette couche peut être composée de plusieurs couches de neuronne. Les entrées des neuronnes sont les sorties de ceux de la couche précèdente.
		\item la couche de sortie : Cette couche nous donne le résultat du réseau.
	\end{enumerate}		

		
	Nous avons défini dans cette partie qu'es ce qu'était un réseau de neuronne et comment est-il formé. Nous allons maintenant voir comment nous pouvons utiliser celui-ci dans divers problème. 
	
	
\section{L'Apprentissage}	
L'une des particularités des réseaux de neuronnes est le fait de pouvoir apprendre au cours du temps. Cette apprentissage, est en réalité l'optimisation d'une fonction issue du réseau utilisé. On appel cette fonction la fonction d'erreur. \\
 
	\subsection{Définition: Fonction d'erreur}
		Soit $C_{x}$ une fonction telle que :	
		  \[ \fonction{C_{x}}{\mathbb{R}^{n+1}}{\mathbb{R}}{(w_1,.....,w_{n+1})}{\frac{1}{2}(y(x)-\Phi_{x}(w_1,.....,w_{n+1}))^{2}}. \]

		avec $(w_1,....,w_n)$ un vecteur poids, $w_{n+1}$ une valeur de seuil choisit pour le réseau de neuronne et $x$ correspondant à une entrée chosit dont $y(x)$ est la valeur attendue après l'application du réseau. Cette fonction est appelée la fonction d'erreur. \\


 \textbf{Remarque }: 
	\begin{enumerate} 
		\item On définit $E$ comme étant un ensemble d'entrée pour un réseau de neuronne particulier dont le résultat voulu est connu. 
		\item La fonction $C_{x}$ définit ne concerne seulement qu'une valeur de l'enssemble $E$. Afin que le réseau de neuronne soit le plus performant possible, nous optimiserons la fonction suivante $\gamma(w_1,.....,w_{n+1}) = \sum_{x \in E} C_{x}(w_1,.....,w_{n+1})$.
		\item L'optimisation de la fonction $\gamma$ dépendra de l'enssemble $E$ que nous devrons fournir.
	\end{enumerate}

L'optimisation de $\gamma$ nous permettra de trouver la  famille $(w_1,.....,w_{n+1})$ qui permettra d'approximer $\gamma$ vers zéro. Nous allons effectuer cette optimisation à l'aide de l'algorithme de descente de gradient.

	\subsection{Définition: Gradient}
		Soit $f: \mathbb{R}^{n} \to \mathbb{R}$ une fonction à plusieurs variables à valeurs réelles. On appelle gradient de $f$, noté $\nabla f$
		\[ \nabla f= \begin{pmatrix} 
					\frac{\partial f}{\partial x_1} \\
					\vdots\\	
					\frac{\partial f}{\partial x_n}\\
				 \end{pmatrix} \] 
\newpage

\subsection{Algorithme du Gradient}
 	
	Cette algorithme va permettre de générer une suite  $x_{1},....,x_{k} \in \mathbb{R}^{n+1}$ jusqu'à que la condition d'arrêt soit satisfaite. On note $x_{1},....,x_{k}$ les différents vecteurs poids que l'algorithme calculera.

	\begin{algorithm}
	\caption{La Descente de Gradient}
	\begin{algorithmic}
	\REQUIRE $x_{0} \in \mathbb{R}^{n+1}$ vecteur poids qu'on choisit initialement \\ 
	$c$ nombre d'étape maximum qu'on autorise  \\ 
	$\varepsilon \ge 0$ seuil qu'on choisit dont le gradient ne doit pas franchir \\ 
	$k=0$
	\WHILE{$\mid \mid \nabla f(x_{k}) \mid \mid  \ge \varepsilon$ and $k \neq c  $}
		\STATE Simulation de calcul de $\nabla f(x_{k})$ \;
		\STATE calcule $\alpha_{k} > 0 $ \;
		\STATE $ x_{k+1} = x_{k} - \alpha_{k} \nabla f(x_{k}) $ \;
		\STATE k++; 
	\ENDWHILE
	\end{algorithmic}
	\end{algorithm} 
\textbf{Remarque }: $\alpha_{k}$ qu'on appelle le pas d'apprentissage doit être chosie avec précaution. En effet, si celui-ci est trops grands, l'algorithme peut amener à une oscilation autour du minimum et si il est trops petit la convergence vers le minimum se ferra très lentement. 
\newline
On calcul le pas d'apprentissage à l'aide de l'algorithme suivant: 
	\begin{algorithm}
	\caption{Calcule du pas d'apprentissage}
	\begin{algorithmic}
	\REQUIRE $x_{0}$ vecteur poids qu'on choisit initialement \\ 
	$k=0$
	\STATE Calculer $\nabla f(x_{K})$ \; 
	\STATE Choisir $\alpha_{k}$ afin de minimiser la fonction $h(\alpha) = f(x_{k}-\alpha \nabla f(x_{k}))$;
	\end{algorithmic}
	\end{algorithm} 
\newline 

\textbf{Remarque } :\begin{enumerate} 
	\item $\alpha_{k}$ sera bien-sûr la valeur pour laquelle on aura $h'(\alpha_{k}) = 0$.
	\item Dans les deux algorithmes précèdent le vecteur $x_{0}$ est choisie aléatoirement. 
	\end{enumerate}
\subsection{Rétropropagation}
Nous avons vu dans la partie précédente, comment nous pouvons minimiser la fonction $\gamma$ à condition d'avoir son gradient. Cette étape
devient très vite fastidieuse lorsque le réseau de neuronne est formé de plusieurs couches de plusieurs neuronnes, car la fonction qui
définira ce réseau sera la composée de toutes les fonctions définissant les neuronnes contenu dans celui-ci. Ce problème va être résolue 
grâce à la rétropropagation qui est une méthode qui va nous permettre de calculer le gradient de n'importe quelle réseau.

\subsection {B-Diagramme}
Pour parler de la rétropropagation  nous nous devons d'introduire une nouvelle structure qui est le B-Diagramme (Backpropagation diagramme).
Ce diagramme représente les neuronnes utilisés dans notre réseau mais dans lesquelle nous stockons dans leurs partie gauche la valeur de la dérivée de leurs fonction et dans leurs partie droite la valeur de leurs fonction pour une entrée donnée.\\
\newline 
La rétropropagation ce divise en deux étapes :
\begin{enumerate}
\item L'étape de feed-forward : Cette étape consite à parcourir notre réseau de gauche à droite afin de calculer pour chaque neuronne, la valeur de sa fonction et de sa dérivée pour une valeur donnée. Une fois calculé et comme dit précèdement chaques valeurs seront stockées dans leurs côté respective. Le résultat stocké à droite sera ensuite transmit au noeud suivant et le procéssus sera réitéré.
\item L'étape de rétropropagation : Dans cette étape le réseau sera parcourus de droite à gauche et la valeur stockée à gauche sera 
utilisée. Cette étape est divisée en plusieurs cas :
\begin{enumerate}
\item La composition  :
\item L'addition : 
\item Les entrées avec poids : 
\end{enumerate}
\end{enumerate} 
	
	
\end{document}
